{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy as sp\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Reshape, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fileName=\"B0007\"\n",
    "a = loadmat(\"d1/\"+fileName+\".mat\")\n",
    "array=[]\n",
    "\n",
    "\n",
    "for i in range(616):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (not typeCycle==\"discharge\"):\n",
    "        continue\n",
    "    array.append(a[fileName][0, 0][0][0][i][3][0][0][6][0][0])\n",
    "print len(array)\n",
    "plt.plot(np.linspace(0, len(array), len(array)), array)\n",
    "'''\n",
    "    \n",
    "    print typeCycle\n",
    "    newDS=open(\"d1/\"+fileName+\"/\"+str(i)+\"_\"+typeCycle+\".csv\", \"w\")\n",
    "    numbOfVect=len(a[fileName][0, 0][0][0][i][3][0][0][0][0])\n",
    "    for k in range(numbOfVect):\n",
    "        if (k>0):\n",
    "            newDS.write(\"\\n\")\n",
    "        for j in range(numbOfFeat):\n",
    "            if (j>0):\n",
    "                newDS.write(\";\")\n",
    "            if (typeCycle==\"discharge\" and j==6):\n",
    "                newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][0]))\n",
    "                continue\n",
    "            if (typeCycle==\"impedance\" and j>2):\n",
    "                newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][0]))\n",
    "                continue\n",
    "            newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][k]))\n",
    "    newDS.close()\n",
    "'''\n",
    "'''\n",
    "array = len(a[fileName][0, 0][0][0])\n",
    "print array\n",
    "            \n",
    "for i in range(616):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (typeCycle==\"impedance\"):\n",
    "        continue\n",
    "    print typeCycle\n",
    "    newDS=open(\"d1/\"+fileName+\"/\"+str(i)+\"_\"+typeCycle+\".csv\", \"w\")\n",
    "    numbOfVect=len(a[fileName][0, 0][0][0][i][3][0][0][0][0])\n",
    "    for k in range(numbOfVect):\n",
    "        if (k>0):\n",
    "            newDS.write(\"\\n\")\n",
    "        for j in range(numbOfFeat):\n",
    "            if (j>0):\n",
    "                newDS.write(\";\")\n",
    "            if (typeCycle==\"discharge\" and j==6):\n",
    "                newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][0]))\n",
    "                continue\n",
    "            if (typeCycle==\"impedance\" and j>2):\n",
    "                newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][0]))\n",
    "                continue\n",
    "            newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][j][0][k]))\n",
    "    newDS.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('d1/B0005/1_discharge.csv', delimiter=';', header=0) \n",
    "dataset = dataset.as_matrix()\n",
    "array1=dataset[10:-20,5] # time\n",
    "array2=dataset[10:-20,1] # cm\n",
    "\n",
    "plt.plot(array1, array2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/380.csv', delimiter=',', header=0) \n",
    "dataset = dataset.as_matrix()\n",
    "array1=dataset[:,1] # time\n",
    "array2=dataset[:,2] # \n",
    "array3=dataset[:,5] # \n",
    "plt.plot(array1, array2, color=\"black\")\n",
    "plt.show()\n",
    "plt.plot(array1, array3, color=\"red\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDS=\"x1/\"\n",
    "fileName=\"B0006\"\n",
    "xS=1\n",
    "a = loadmat(\"d1/\"+fileName+\".mat\")\n",
    "array=[]\n",
    "newDS=open(pathDS+\"y_train.csv\", \"w\")\n",
    "for i in range(616):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (not typeCycle==\"discharge\"):\n",
    "        continue\n",
    "    for h in range(xS):\n",
    "        newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][6][0][0]))\n",
    "        newDS.write(\"\\n\")\n",
    "    array.append(a[fileName][0, 0][0][0][i][3][0][0][6][0][0])\n",
    "print len(array)\n",
    "newDS.close()\n",
    "#plt.plot(np.linspace(0, len(array), len(array)), array)\n",
    "fileName=\"B0018\"\n",
    "a = loadmat(\"d1/\"+fileName+\".mat\")\n",
    "array=[]\n",
    "newDS=open(pathDS+\"y_test.csv\", \"w\")\n",
    "for i in range(319):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (not typeCycle==\"discharge\"):\n",
    "        continue\n",
    "    newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][6][0][0]))\n",
    "    if (not i==613):\n",
    "        newDS.write(\"\\n\")\n",
    "    array.append(a[fileName][0, 0][0][0][i][3][0][0][6][0][0])\n",
    "print len(array)\n",
    "newDS.close()\n",
    "#plt.plot(np.linspace(0, len(array), len(array)), array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName=\"B0006\"\n",
    "pathDS=\"x1/\"\n",
    "a = loadmat(\"d1/\"+fileName+\".mat\")\n",
    "array=[]\n",
    "newDS=open(pathDS+\"xd_train.csv\", \"w\")\n",
    "for i in range(616):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    numbOfVect=len(a[fileName][0, 0][0][0][i][3][0][0][0][0])    \n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (not typeCycle==\"discharge\"):\n",
    "        continue\n",
    "    print i, numbOfVect\n",
    "    ar=np.linspace(0, numbOfVect-1, 10, dtype=int)\n",
    "    for h in range(xS):\n",
    "        for j in ar:\n",
    "            for k in range (6): \n",
    "                newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][k][0][j]))\n",
    "                if (not (j==ar[-1] and k==5)):\n",
    "                    newDS.write(\";\")\n",
    "        newDS.write(\"\\n\")\n",
    "    #array.append(a[fileName][0, 0][0][0][i][3][0][0][6][0][0])\n",
    "#print len(array)\n",
    "newDS.close()\n",
    "#plt.plot(np.linspace(0, len(array), len(array)), array)\n",
    "fileName=\"B0018\"\n",
    "a = loadmat(\"d1/\"+fileName+\".mat\")\n",
    "array=[]\n",
    "newDS=open(pathDS+\"xd_test.csv\", \"w\")\n",
    "for i in range(319):\n",
    "    numbOfFeat=len(a[fileName][0, 0][0][0][i][3][0][0])\n",
    "    numbOfVect=len(a[fileName][0, 0][0][0][i][3][0][0][0][0])    \n",
    "    #print numbOfVect\n",
    "    typeCycle=a[fileName][0, 0][0][0][i][0][0]\n",
    "    if (not typeCycle==\"discharge\"):\n",
    "        continue\n",
    "    ar=np.linspace(0, numbOfVect-1, 10, dtype=int)\n",
    "    for j in ar:\n",
    "        for k in range (6): \n",
    "            newDS.write(str(a[fileName][0, 0][0][0][i][3][0][0][k][0][j]))\n",
    "            if (not (j==ar[-1] and k==5)):\n",
    "                newDS.write(\";\")\n",
    "    newDS.write(\"\\n\")\n",
    "    #array.append(a[fileName][0, 0][0][0][i][3][0][0][6][0][0])\n",
    "#print len(array)\n",
    "newDS.close()\n",
    "#plt.plot(np.linspace(0, len(array), len(array)), array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importData():\n",
    "    X_train = pd.read_csv('x10/xd_train.csv', delimiter=';', header=None)\n",
    "    y_train=pd.read_csv('x10/y_train.csv', header=None)\n",
    "    X_test=pd.read_csv('x10/xd_test.csv', delimiter=';', header=None)\n",
    "    y_test=pd.read_csv('x10/y_test.csv', header=None)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "def normalizeData(X_train, X_test):\n",
    "    X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "    X_test = (X_test - X_test.mean())/X_test.std()\n",
    "    return X_train, X_test\n",
    "np.random.seed(42)\n",
    "x_train, y_train, x_test, y_test = importData()\n",
    "#x_train, x_test = normalizeData(x_train, x_test)\n",
    "#print x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 60)                3660      \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 60, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 60, 60)            14880     \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 60)                29040     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 47,641\n",
      "Trainable params: 47,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/31\n",
      "1680/1680 [==============================] - 10s - loss: nan    \n",
      "Epoch 2/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 3/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 4/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 5/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 6/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 7/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 8/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 9/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 10/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 11/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 12/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 13/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 14/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 15/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 16/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 17/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 18/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 19/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 20/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 21/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 22/31\n",
      "1680/1680 [==============================] - 6s - loss: nan     \n",
      "Epoch 23/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 24/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 25/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 26/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 27/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 28/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 29/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 30/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n",
      "Epoch 31/31\n",
      "1680/1680 [==============================] - 7s - loss: nan     \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e49e7c649189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mzLSMT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMRes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#plt.figure(figsize=(15,15))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m132\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m132\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \"\"\"\n\u001b[1;32m    230\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 231\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    232\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    233\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/sklearn/metrics/regression.pyc\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \"\"\"\n\u001b[1;32m     74\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "def LSTMRes(X_train, X_test, y_train, y_test):\n",
    "    X_train, X_test, y_train, y_test= X_train.as_matrix(), X_test.as_matrix(), y_train.as_matrix(), y_test.as_matrix()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(60,)))\n",
    "    model.add(Reshape((60,1)))\n",
    "    model.add(LSTM(60, return_sequences=True))\n",
    "    model.add(LSTM(60, dropout=0.3, recurrent_dropout=0.32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    print(model.summary())\n",
    "    model.fit(X_train, y_train, epochs=31)# validation_data=(X_test, y_test))    zLSMT = model.predict_proba(X_test)\n",
    "    zLSMT = model.predict(X_test)\n",
    "    y_res=open('y_testLSTM.csv', 'w')\n",
    "    y_res.write('\\n'.join(str(v[0]) for v in zLSMT))  \n",
    "    return zLSMT\n",
    "res = LSTMRes(x_train, x_test, y_train, y_test)\n",
    "print(mean_squared_error(res, y_test))\n",
    "#plt.figure(figsize=(15,15))\n",
    "plt.plot(np.linspace(0, 132, 132), res)\n",
    "plt.plot(np.linspace(0, 132, 132), y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
